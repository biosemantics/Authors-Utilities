---
title: "Capstone: A Custom _Carex_ Color Palette"
author: "Noah Giebink"
date: "5/8/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
```

## ABSTRACT


Color is a conspicuous and variable trait across plants, yet it is challenging to glean taxonomic insight from color descriptions when the language used to describe color traits is inconsistent. The objective of the present study is to encourage a controlled color vocabulary by building a custom color palette tool which helps authors choose standardized color descriptions for plant specimens. Focusing on the genus _Carex_, I integrated data from author descriptions in Flora of North America Vol. 23 with corresponding ground truth color measurements to map real-life quantitative color values with the language used to describe them. Color descriptions fell within a small set of frequent color classes: brown, green, red, white, yellow-green, and yellow-brown. However, the striking overlap in the measured color values for samples given each of these names by authors further necessitates a controlled color vocabulary. Given color values and the color class for a subset of samples, I compared manual and machine learning approaches for predicting color class boundaries and present a proposed color palette for each.


## INTRODUCTION  

Plant color traits are of widespread research interest due to their significance to the ecology and evolution of plants, from mediating pollinator interactions to thermoregulation (Rosas‐Guerrero et al., 2014; Dick et al., 2011). Though strides have been made to encourage controlled vocabularies for plants which would drastically increase our ability to leverage computational analyses of taxonomic descriptions (Endara et al., 2017), the inconsistency and subjectivity of color description hinders progress.  

##### Questions  


For the present work, I addressed three major questions which are key to developing a controlled color vocabulary:


* _Q1. Can we create a custom color palette which uses both existing color description language and real values from *Carex* spp. sample measurements?_
* _Q2. Is a manual approach best for creating a palette or is it possible to automate the process via machine learning?_ 
* _Q3. How do existing author descriptions of colors compare with the visual appearance of measured colors?_


A key step to answering _Q1_ is finding the appropriate color space representation for our sample measurements in order to distinguish colors in a way that is perceptually meaningful to users. While sRGB is a commonplace quantitative representation for colors, it is more suited to interpretation by machines than for capturing perceptual differences between colors. CIE Lab space, referred to as L\*a\*b\* is specifically useful for encoding small differences between colors across axes that are relevant to human color perception. Axes a* and b* are based on the opponent process theory of color vision, where red opposes green and yellow opposes blue (Hurvich & Jameson, 1957). Centered at zero, negative values of a* are more green and positive values are red; negative values of b* are more blue and positive values are more yellow. color values in L\*a\*b\* space are independent of lightness, encoded separately in L\*. This marks a critical contrast with sRGB space in which color value cannot be disentangled from lightness. This is practically challenging for my purpose since similar colors may be distant in color space merely due to difference in brightness, not class membership. 

I investigated the efficacy of representing real sample colors in L\*a\*b\* space compared to sRGB space, for use in both manual and automated approaches to developing a custom *Carex* color palette. Finally, I used the color class boundaries predicted by these approaches to visualize incongruities in the existing, uncontrolled vocabulary for color descriptions.


## METHODS  

#### Data Preparation  

##### Data Sources  


I joined two data sources: species level color descriptions from the Flora of North America Vol. 23 (henceforth "author descriptions") (FNA; www.eflora.org.), and species to subspecies level ground truth, sRGB channel color measurements of specimen images (henceforth color measurements"). Specimen images for a total of 456 species were curated, mostly from online data sharing platforms (e.g. SeiNet, Intermountain Regional Herbarium Network). Specimens were filtered for quality such that all were high resolution, lacked preventable discoloration, and had a color control reference. For species whose specimens failed to meet these standards, original images were captured the herbaria of the Canadian Museum of Nature (CAN), Agriculture and Agri-Food Canada (DAO), or the Marie-Victorin Herbarium (MT). sRGB values were taken from each specimen over several pixels using ImageJ (ver. 1.50i; Schindelin et al., 2012). Author descriptions were specific to tissues including leaf, male scale, perigynium, female scale, and cataphyll. For both author descriptions and color measurements, I discarded observations from male and female scales because these were the average of the margin, blade, and axis and were thus not "real" colors shown on the specimen. I used the joined data set with both author descriptions and color measurements to manually sort colors into classes and further partitioned the data into train and test sets to train support vector machines for an automated approach. Table 1 includes sample sizes of each data set used. 



```{r, echo=FALSE}
sample_sizes <- data.frame('Data Set' = c('Color Measurements', 'Author Descriptions', 'Train', 'Train Down Sampled',  'Test'), 'Observations' = c(2883, 956, 631, 215, 161))
kable(sample_sizes, col.names = gsub("[.]", " ", names(sample_sizes)), caption = 'Sample size for each data set.')
```


#### Color Classes


I mined author description texts to identify the color classes present (R package 'tm'; Feinerer et al., 2008). I first found the most frequent single-word color terms, not including stop words, used in author descriptions. I selected the most frequent terms (classes) and manually grouped the remaining terms with these classes as synonyms for their respective class, according to my subjective judgement of equivalence (Table 2). I validated these color classes and synonym groupings by subjecting them to review by three *Carex* experts. 



```{r, echo = FALSE}
terms <- data.frame('Class' = c('Green', 'Brown', 'Red', 'White', 'Yellow-Brown', 'Yellow-Green'), 'Synonyms' = c('olive', 'castaneous, chestnut, copper, bronze, tan, tawny', 'maroon', 'gray, glaucous', 'green-yellow, yellow, golden, straw, gold', 'yellow'))

```



I converted each author description string into a single color class (henceforth "author label") based on the color class terms and synonyms present in the string. This wass a two-step process applied to each class and its synonyms: first, I filtered observations containing any one of the synonyms in a color class; second, I filtered the result of the first step to contain only the observations unique to each color class so that no observation had more than one color class. The result was a single color class label for each observation.

##### Color Space Transformation  


I engineered features in L\*a\*b\* space from sRGB input values using the convertColor function from the built-in grDevices package (R Core Team, 2021). 


#### Manual Approach - Thresholds  


I relied on natural breaks in the distribution of samples along a\* and b\* axes to set thresholds which divide colors. I continued to manually separate the data this way into sequentially smaller bins until they resembled the color classes brown, green, red, white, yellow-brown, and yellow-green. I visualize the full sequence of divisions in Figures 1-4. I color-code figures 1-4 and 6-8 with the actual values of samples which represent that respective color class or distribution of colors. I found each representative "centroid" by taking the mean a\* - b\* value of a set of samples, then calculating the nearest neighbor to the mean, an actual measurement. A limitation of this method is that it can only divide samples (create "thresholds") along vertical and horizontal lines: intercepts along the a\* and b* axes, and rectangles formed via the combination of these thresholds.


#### Support Vector Machine Approach  


To overcome the limited division lines limitation of the manual thresholds approach, and because the author label data--while noisy--appear to be linearly or nearly linearly separable (Figure 6, bottom right), I trained two SVM models to predict color class (Meyer et al., 2021), one with the default radial kernel and the other linear. To overcome the class imbalance, I down sampled the data so that all classes had the same n, equal to the smallest class (Caret R package; Kuhn, 2020). I removed the white class entirely from the training and testing data since it would cause to great a reduction in the sample size for the other classes. Finally, I increased the regularization hyperparameter C from default 1 to 0.5 to penalize the model less for misclassifying noisy points. Finally, I calculated class-wise precision, recall, and f1 scores for both models and selected the model with the greatest mean f1 for the ultimate color palette.


```{r, echo=FALSE}
model_samples <- readRDS('model/model_samples.rds')
kable(model_samples, caption = "Class-wise sample sizes for developing thresholds ('Full Labeled Set') and SVM models ('Train Down Sampled (no white)'). SVM models and thresholds performance were assessed with a common test set (Test), except class 'white' was excluded from SVM model assessment.")
```


#### Final Color Palette


I split the full data set (n = 2883; see Table 1) along color class thresholds defined via the manual thresholds method and predicted color class from a\* and b\* features using the best performing SVM. I further separated each resulting color class into light, medium, and dark using k-means on the L\* variable, with k=3. To choose a reasonable number of color samples for users to select from and visualize, I sampled five values in each lightness level of each color class predicted by each approach. I down sampled using a custom algorithm which calculates the mean distance to k nearest neighbors for each point ("mean_dist"; default k = 3 used here), and samples the points with probability equal to the normalized mean_dist such that points with lower mean_dist (i.e. nearer neighbors) are less likely to be sampled. This allowed me to select a sample of colors to present in the palette which should be less redundant perceptually than a simple random sample.


## RESULTS and DISCUSSION  


#### Q1: Custom Color Palette  


The Red and Green axes of sRGB space contained most of the variance in color values (Figure 5). This may be due to the fact that natural vegetative tissue on plant specimens, including *Carex* spp., is unlikely to be blue.  Therefore, I visually compared the differences in representation between R-G and a\*-b\* spaces (Figure 6).
Representing color samples in L\*a\*b\* space led to a greater spread in values and improved the linear separability of the color classes. Transforming sRGB measurements into perceptually-oriented L\*a\*b\* space made it feasible to create a custom color palette from existing color language and ground-truth _Carex_ color measurements.


#### Q2: Manual vs. Automated Approach  


The linear SVM had the best performance against the author labels in the test set (multiclass mean f1 = 0.4757042), followed by the radial SVM (multiclass mean f1 = 0.4573148), and the manual thresholds approach (mean multiclass f1 = 0.3998657 factoring out performance on 'white' class for equal comparison; else mean multiclass f1 = 0.388777). Detailed multiclass precision, recall, and f1 scores are summarized in tables 3 and 4.



```{r, echo=FALSE}
score_lin <- readRDS('performance/score_lin.rds')
score_thresholds <- readRDS('performance/score_thresholds.rds')
kable(score_lin, caption = 'Class-wise precision, recall, and f1 scores for Linear SVM')
kable(score_thresholds, caption = 'Class-wise precision, recall, and f1 scores for thresholds')
```



While the SVM had greater performance classifying authors' labels (possibly because the manual approach was limited to horizontal and vertical lines in color space), the manual thresholds approach appears qualitatively at least as effective (Figure 9). This qualitative improvement may be due to the fact that the color language used by authors is inconsistent to begin with. So, while the SVM stays truer to author descriptions, my manual thresholds approach may be a better representation of true colors. However, the SVM provides the benefit of automation, speed, and easier reproducibility. Thus, I present two feasible methods for designing a sample-based color palette for a controlled vocabulary which can be employed based on the needs and goals of the curator.


#### Q3: Author Descriptions vs. Appearance  


Notably, the thresholds method did not rely on learning the author labels; matches between author labels and classes via the thresholds approach appeared when author labels agreed with my color designations. This justified using color class predictions from the thresholds approach to visually inspect the consistency of author descriptions, measured by the frequency that each author label appeared in the "correct" color class (Figure 8). Qualitatively, there is a great deal of overlap in color classes according to author labels in both R-G and a\*b\* space (Figure 7). Qualitatively, brown, green, and white contained majority "correct" author labels, whereas for red, yellow-brown, and yellow-green, the majority author label was "incorrect." While some variability of author labels is expected when pit against a color classification scheme that is not perfectly congruent with author labels (a model perfectly accurate at predicting author labels would show the author label to be correct each time), some of the deviance from predicted color class is certainly attributable to the striking overlap in the measured values of samples in each author label (see figure 7). Regardless, the variety in color descriptions given to visually similar colors necessitates a controlled color vocabulary. 


#### Future Work  


The next stage will be to integrate the color palette produced here with web ontogeny software. Then, we will perform usability experiments and test whether the ability to make selections from a color palette containing a subset of real sample values (as shown here) improves consistency of color descriptions.


### CODE AND REPRODUCIBILITY  


All code and data necessary to reproduce this work can be found in [this GitHub Repository](https://github.com/biosemantics/Authors-Utilities/tree/master/color_processing).


## LITERATURE CITED    


Dick, C. A., Buenrostro, J., Butler, T., Carlson, M. L., Kliebenstein, D. J., & Whittall, J. B. (2011). Arctic Mustard Flower Color Polymorphism Controlled by Petal-Specific Downregulation at the Threshold of the Anthocyanin Biosynthetic Pathway. PLOS ONE, 6(4), e18230. https://doi.org/10.1371/journal.pone.0018230


Endara, L., Cole, H. A., Burleigh, J. G., Nagalingum, N. S., Macklin, J. A., Liu, J., Ranade, S., & Cui, H. (2017). Building the “Plant Glossary”—A controlled botanical 
vocabulary using terms extracted from the Floras of North America and China. Taxon, 66(4), 953–966. https://doi.org/10.12705/664.9


Feinerer, I. & K. Hornik (2020). tm: Text Mining Package. R package version 0.7-8. https://CRAN.R-project.org/package=tm


Hurvich, L. M., & Jameson, D. (1957). AN OPPONENT-PROCESS THEORY OF COLOR VISION. Psychological Review, 64(6), 21.


Kuhn, M. (2020). caret: Classification and Regression Training. R package version 6.0-86. https://CRAN.R-project.org/package=caret

Meyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., and F. Leisch (2021). e1071: Misc Functions of the Department of Statistics,
  Probability Theory Group (Formerly: E1071), TU Wien. R package version 1.7-6. https://CRAN.R-project.org/package=e1071

R Core Team (2021). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL
  https://www.R-project.org/.


Rosas‐Guerrero, V., Aguilar, R., Martén‐Rodríguez, S., Ashworth, L., Lopezaraiza‐Mikel, M., Bastida, J. M., & Quesada, M. (2014). A quantitative review of pollination syndromes: Do floral traits predict effective pollinators? Ecology Letters, 17(3), 388–400. https://doi.org/10.1111/ele.12224


Schindelin, J., Arganda-Carreras, I., Frise, E., Kaynig, V., Longair, M., Pietzsch, T., Preibisch, S., Rueden, C., Saalfeld, S., Schmid, B., Tinevez, J.-Y., White, D. J., Hartenstein, V., Eliceiri, K., Tomancak, P., & Cardona, A. (2012). Fiji: An open-source platform for biological-image analysis. Nature Methods, 9(7), 676–682. https://doi.org/10.1038/nmeth.2019


![From left: Green-Red and Blue-Yellow divisions in the whole data set along natural breaks in distributions of color samples along a* (green-red) and b* (blue-yellow) axes of L\*a\*b*. Portions of the distributions are colored according to the sRGB values of centroid samples for corresponding to that portion of the distribution (see methods).](plots/final/splits_main.png)


![From left: brown-yellow-brown, brown-red, and red-brown (brown appears in two regions of L\*a\*b\* space) divisions among a\* values greater than -2 (after splitting on natural break in Figure 1, left). Divisions appear along natural breaks in distributions of color samples along a* (green-red) and b* (blue-yellow) axes of L\*a\*b* space. Portions of the distributions are colored according to the sRGB values of centroid samples for corresponding to that portion of the distribution (see methods).](plots/final/splits_brownish.png)


![From left: green-yellow-green and yellow-green-green (green appears in two regions of L\*a\*b\* space) divions among a\* values less than -2 (after splitting on natural break in Figure 1, left). Divisions appear along natural breaks in distributions of color samples along a* (green-red) and b* (blue-yellow) axes of L\*a\*b* space. Portions of the distributions are colored according to the sRGB values of centroid samples for corresponding to that portion of the distribution (see methods).](plots/final/splits_greenish.png)


![From left: green-white-brown and white-green divions among samples with author label "white." Divisions appear along natural breaks in distributions of color samples along a* (green-red) and b* (blue-yellow) axes of L\*a\*b* space. Portions of the distributions are colored according to the sRGB values of centroid samples for corresponding to that portion of the distribution (see methods).](plots/final/splits_whitish.png)


![Red and Green axes in sRGB space contain most of the variance in color values.](plots/final/RGB_axis_distributions.png)


![Points are colored according to the sRGB values of the centroid point for their class (see methods). The centroid point used for each class is indicated in red.](plots/final/spaces_RGB_vs_lab.png)


![Color spaces reflecting spatial distribution of each class, predicted on the full data set by the thresholds approach (left) and a linear SVM (right) (n = 2883; see Table 1). Thresholds are shown as rectangles, colored according to the class they separate. Points are colored according to the sRGB values of the centroid point for their class (see methods). The centroid point used for each class is indicated in red.](plots/final/color_spaces_full.png)


![Frequency of author labels given to each color class, as classified via the thresholds approach.](plots/final/label_vs_color.png)


![Final color palettes produced by the thresholds approach (top) and a linear SVM (bottom).](plots/final/palettes.png)